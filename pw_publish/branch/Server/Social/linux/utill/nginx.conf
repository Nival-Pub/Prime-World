user  ec2-user;
worker_processes  1;

error_log  /home/ec2-user/pw/logs/error.log;
pid        /home/ec2-user/pw/logs/nginx.pid;
worker_rlimit_nofile 8192;

#pid        logs/nginx.pid;

events {
    worker_connections  4096;
    accept_mutex  off; # иначе не будет работать много worker_processes
}

http {
    #include       mime.types;
    #default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /home/ec2-user/pw/logs/access.log;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    gzip  on;
    gzip_min_length  1100;
    gzip_buffers     16 128k;
    gzip_types       text/plain;

    ## load balancer: делим запросы поровну между всеми подсерверами (портами)
    upstream  balance  {
        server   127.0.0.1:8801 max_fails=0 fail_timeout=3s; ##DEBUG: в отладке отправляем всё на один (отладочный) сервер
        server   127.0.0.1:8802 max_fails=0 fail_timeout=3s;
    }

    ## доступ к конкретному серверу №1 (на котором, видимо, находится конкретный активный user context)
    upstream  one  {
        server   127.0.0.1:8801 max_fails=0 fail_timeout=3s;
    }

    ## доступ к конкретному серверу №2 (на котором, видимо, находится конкретный активный user context)
    upstream  two  {
        server   127.0.0.1:8802 max_fails=0 fail_timeout=3s;
    }

    server {
        listen       88;
        server_name  ec2-50-16-18-0.compute-1.amazonaws.com;

        ## доступ к конкретному серверу №1 (на котором, видимо, находится конкретный активный user context)
        location /one {
            proxy_pass  http://one;
            proxy_connect_timeout      5;
            proxy_send_timeout         30;
            proxy_read_timeout         30;
        }

        ## доступ к конкретному серверу №2 (на котором, видимо, находится конкретный активный user context)
        location /two {
            proxy_pass  http://two;
            proxy_connect_timeout      5;
            proxy_send_timeout         30;
            proxy_read_timeout         30;
        }

        ## load balancer: запросы к localhost голому делим поровну между всеми подсерверами (портами)
        location = / {
            proxy_pass  http://balance;

            proxy_connect_timeout      5;
            proxy_send_timeout         30;
            proxy_read_timeout         30;
        }

        ## запросы насчет иконок и роботов просто посылаем
        location = /favicon.ico {
            deny all;
        }
        location = /robots.txt {
            deny all;
        }
    }

}